{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "629bca1d",
   "metadata": {},
   "source": [
    "## Train the baseline model using classification loss only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29c24abe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-07T22:32:57.275634Z",
     "iopub.status.busy": "2022-08-07T22:32:57.274969Z",
     "iopub.status.idle": "2022-08-07T22:32:58.878850Z",
     "shell.execute_reply": "2022-08-07T22:32:58.877957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme(color_codes=True)\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModelForImageClassification, AutoConfig, AutoFeatureExtractor\n",
    "from transformers.utils import logging\n",
    "from transformers import DefaultDataCollator\n",
    "\n",
    "logging.set_verbosity(transformers.logging.ERROR) \n",
    "logging.disable_progress_bar() \n",
    "\n",
    "p = os.path.abspath('../')\n",
    "sys.path.insert(1, p)\n",
    "\n",
    "from src.utils.utils import *\n",
    "from src.wordnet_ontology.wordnet_ontology import WordnetOntology\n",
    "\n",
    "from torch.utils.data import DataLoader \n",
    "from functools import partial \n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
    "import evaluate\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import math\n",
    "import copy\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import random\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from datasets import Image\n",
    "from datasets import load_dataset\n",
    "import wn \n",
    "\n",
    "seed=7361\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "n_excluded_classes = int(556 * 0.05)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "wn_en = wn.Wordnet('omw-en')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c2a6d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imagenet_sketch (/mnt/HDD/kevinds/sketch/./cache/imagenet_sketch/default/0.0.0/9bbda26372327ae1daa792112c8bbd2545a91b9f397ea6f285576add0a70ab6e)\n"
     ]
    }
   ],
   "source": [
    "mapping_filename = './data/external/imagenet/LOC_synset_mapping.txt'\n",
    "wn = WordnetOntology(mapping_filename)\n",
    "\n",
    "vocab = torch.load('./models/vocab.pt')\n",
    "\n",
    "sketch = load_dataset(\"imagenet_sketch\", split='train', cache_dir='./cache/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97b7a97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=300x300>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sketch[0]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ed872ef",
   "metadata": {
    "code_folding": [
     1
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /mnt/HDD/kevinds/sketch/./cache/imagenet_sketch/default/0.0.0/9bbda26372327ae1daa792112c8bbd2545a91b9f397ea6f285576add0a70ab6e/cache-4bdc4125347390de.arrow\n"
     ]
    }
   ],
   "source": [
    "def get_hclass(x):\n",
    "    _class = wn.class_for_index[x['label']] \n",
    "    return { \n",
    "        'label': vocab[wn.hypernym(_class)] \n",
    "    }\n",
    "\n",
    "sketch = sketch.map(get_hclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94deb6e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_classes = list(set(sketch['label']))\n",
    "excluded_classes = [random.choice(_classes) for i in range(n_excluded_classes)]\n",
    "dt = train_test_split(sketch, excluded_labels=excluded_classes)\n",
    "train, test = dt['train'], dt['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b53d46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n02085374',\n",
       " 'n04490091',\n",
       " 'n01632047',\n",
       " 'n12056217',\n",
       " 'n02329401',\n",
       " 'n04015204',\n",
       " 'n04100174',\n",
       " 'n02087122',\n",
       " 'n02453611',\n",
       " 'n02796623',\n",
       " 'n03211117',\n",
       " 'n03706653',\n",
       " 'n04202417',\n",
       " 'n02887209',\n",
       " 'n04549122',\n",
       " 'n01703569',\n",
       " 'n04586421',\n",
       " 'n12157056',\n",
       " 'n03953416',\n",
       " 'n04520170',\n",
       " 'n01816887',\n",
       " 'n02534734',\n",
       " 'n04187061',\n",
       " 'n06595351',\n",
       " 'n04151581',\n",
       " 'n02268148',\n",
       " 'n15074962']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vocab.get_itos()[_cl] for _cl in excluded_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd4851c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "_transforms = transforms.Compose([\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.Resize((feature_extractor.size, feature_extractor.size)),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std),\n",
    "])\n",
    "\n",
    "def get_pixel_values(examples):\n",
    "    images = [ _transforms(image.convert(\"RGB\")) for image in examples['image']]\n",
    "    examples[\"pixel_values\"] = images\n",
    "    del examples[\"image\"]\n",
    "    return examples\n",
    "\n",
    "train = train.with_transform(get_pixel_values)\n",
    "test = test.with_transform(get_pixel_values)\n",
    "collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a8ee4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.hub.set_dir('../cache')\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224-in21k\", \n",
    "    num_labels=len(vocab),\n",
    "    label2id=vocab.get_stoi(),\n",
    "    id2label={i:l for i, l in enumerate(vocab.get_itos())}\n",
    ")\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "data_collator = DefaultDataCollator()\n",
    "\n",
    "cb = StoreLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18c15508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using cuda_amp half precision backend\n",
      "/home/kevinds/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 37863\n",
      "  Num Epochs = 16\n",
      "  Instantaneous batch size per device = 36\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 288\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 2096\n",
      "  Number of trainable parameters = 86226220\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 23.69 GiB total capacity; 3.96 GiB already allocated; 80.38 MiB free; 4.11 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 44\u001b[0m\n\u001b[1;32m     16\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     17\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./aaa/baseline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     fp16\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     35\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     36\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mfeature_extractor\n\u001b[1;32m     42\u001b[0m )\n\u001b[0;32m---> 44\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:1501\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1498\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1499\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1500\u001b[0m )\n\u001b[0;32m-> 1501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:1749\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1747\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1749\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1752\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1754\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1755\u001b[0m ):\n\u001b[1;32m   1756\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:2508\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2507\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2508\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2511\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:2540\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2539\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2540\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2541\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2542\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/vit/modeling_vit.py:776\u001b[0m, in \u001b[0;36mViTForImageClassification.forward\u001b[0;34m(self, pixel_values, head_mask, labels, output_attentions, output_hidden_states, interpolate_pos_encoding, return_dict)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;124;03m    Labels for computing the image classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    774\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 776\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpolate_pos_encoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolate_pos_encoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    785\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    787\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output[:, \u001b[38;5;241m0\u001b[39m, :])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/vit/modeling_vit.py:565\u001b[0m, in \u001b[0;36mViTModel.forward\u001b[0;34m(self, pixel_values, bool_masked_pos, head_mask, output_attentions, output_hidden_states, interpolate_pos_encoding, return_dict)\u001b[0m\n\u001b[1;32m    559\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    561\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    562\u001b[0m     pixel_values, bool_masked_pos\u001b[38;5;241m=\u001b[39mbool_masked_pos, interpolate_pos_encoding\u001b[38;5;241m=\u001b[39minterpolate_pos_encoding\n\u001b[1;32m    563\u001b[0m )\n\u001b[0;32m--> 565\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    572\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    573\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm(sequence_output)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/vit/modeling_vit.py:416\u001b[0m, in \u001b[0;36mViTEncoder.forward\u001b[0;34m(self, hidden_states, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    410\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    411\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    412\u001b[0m         hidden_states,\n\u001b[1;32m    413\u001b[0m         layer_head_mask,\n\u001b[1;32m    414\u001b[0m     )\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/vit/modeling_vit.py:355\u001b[0m, in \u001b[0;36mViTLayer.forward\u001b[0;34m(self, hidden_states, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    351\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    352\u001b[0m     head_mask: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    353\u001b[0m     output_attentions: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    354\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor], Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[0;32m--> 355\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayernorm_before\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# in ViT, layernorm is applied before self-attention\u001b[39;49;00m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    361\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/vit/modeling_vit.py:296\u001b[0m, in \u001b[0;36mViTAttention.forward\u001b[0;34m(self, hidden_states, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    292\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    293\u001b[0m     head_mask: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    294\u001b[0m     output_attentions: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    295\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor], Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[0;32m--> 296\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    300\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/vit/modeling_vit.py:225\u001b[0m, in \u001b[0;36mViTSelfAttention.forward\u001b[0;34m(self, hidden_states, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    222\u001b[0m attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_head_size)\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66;03m# Normalize the attention scores to probabilities.\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_probs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py:1841\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1839\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1841\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1842\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1843\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 23.69 GiB total capacity; 3.96 GiB already allocated; 80.38 MiB free; 4.11 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "accuracyk = evaluate.load(\"KevinSpaghetti/accuracyk\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    \n",
    "    k=5\n",
    "    top1_pred = np.argmax(logits, axis=-1, keepdims=True)\n",
    "    top5_pred = np.argpartition(logits, -k, axis=-1)[:, -k:]\n",
    "    \n",
    "    top1 = accuracyk.compute(predictions=top1_pred, references=labels)\n",
    "    top5 = accuracyk.compute(predictions=top5_pred, references=labels)\n",
    "    return {\n",
    "        'top1': top1['accuracy'],\n",
    "        'top5': top5['accuracy']\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/baseline\",\n",
    "    num_train_epochs=16,\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=36,\n",
    "    per_device_eval_batch_size=36,\n",
    "    gradient_accumulation_steps=8,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=200,\n",
    "    report_to=\"none\",\n",
    "    dataloader_num_workers=4,\n",
    "    dataloader_pin_memory=True,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=test,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=feature_extractor\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
