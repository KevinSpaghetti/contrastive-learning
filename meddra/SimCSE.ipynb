{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ls9pStRPrlQB"
   },
   "source": [
    "## Train the model using the SimCSE framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U8qs0SuorsrU"
   },
   "outputs": [],
   "source": [
    "# install SimCSE required dependencies\n",
    "!pip install simcse\n",
    "!pip install torch==1.7.1+cu110 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install rdflib\n",
    "!git clone https://github.com/princeton-nlp/SimCSE simcse\n",
    "!pip install -r /content/simcse/requirements.txt\n",
    "!pip install dill==0.3.2\n",
    "!pip install transformers\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7jryzbIgjAp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from simcse import SimCSE\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import csv\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset, load_dataset, Split\n",
    "\n",
    "seed = 7631\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lI4jKIxanGUe"
   },
   "outputs": [],
   "source": [
    "def get_seen_unseen_split(train_df, test_df, label_col):\n",
    "    seen_labels = set(train_df[label_col])    \n",
    "    seen = test_df.filter(lambda x: x[label_col] in seen_labels)\n",
    "    unseen = test_df.filter(lambda x: x[label_col] not in seen_labels)\n",
    "    return seen, unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229,
     "referenced_widgets": [
      "68d83eb0cfb2466a8b99cca20af8646e",
      "439a976ff3a14b95890337d4814d16f6",
      "0d58d93091f547539d632b0f12c695da",
      "d3b9e3572221476d8edb99f1ecd3260f",
      "0a49c2971c054d76b224afdd1653e6f1",
      "3ea6d36ffdd14c11bd0b14a7c8794223",
      "b72ed9219c3a42a6a1b0452c6e2d43e1",
      "890907bcbe9a4f0b99f323ae1e00716b",
      "507bfa42c46a4833a408cbdb425cd8b8",
      "c2880ffc5bdb45daa6143391be4b265c",
      "dc2ca34783154f89b350c8e5079f2635",
      "1b5bb989bbc941339ed88a300828c8a8",
      "b9a717fa3ee84b37be66d520f274c62d",
      "3774ec9a6e574255a78006688562de6e",
      "7366edda2c3e4fb5b62dfb0995ca7b7b",
      "c0279fd7382d4cf9b89fec18e862e0b8",
      "54a743cc80154a1a9a742daa0932cc04",
      "18b73b2cda9f492c970f36e8f547fa8f",
      "41f1e7ecd7b64bfdae4c287da23d8cef",
      "81da7e86a82f4e70a8a5a4a5f418d333",
      "d4a5cd45173341348193cd813ed0e2de",
      "0e49fb0361da49978ab25e3f4f3857ca"
     ]
    },
    "id": "CokjggOC7mzt",
    "outputId": "e260f449-0dc5-4650-8c80-9717bc9f6153"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration KevinSpaghetti--smm4h20-44edae7ca61b57c9\n",
      "WARNING:datasets.builder:Found cached dataset parquet (/root/.cache/huggingface/datasets/KevinSpaghetti___parquet/KevinSpaghetti--smm4h20-44edae7ca61b57c9/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d83eb0cfb2466a8b99cca20af8646e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration KevinSpaghetti--cadec-706fe2a599dfdc15\n",
      "WARNING:datasets.builder:Found cached dataset parquet (/root/.cache/huggingface/datasets/KevinSpaghetti___parquet/KevinSpaghetti--cadec-706fe2a599dfdc15/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5bb989bbc941339ed88a300828c8a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration KevinSpaghetti--all_pts-64119da2103bc4d3\n",
      "WARNING:datasets.builder:Found cached dataset parquet (/root/.cache/huggingface/datasets/KevinSpaghetti___parquet/KevinSpaghetti--all_pts-64119da2103bc4d3/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24571\n"
     ]
    }
   ],
   "source": [
    "smm4h20 = load_dataset('KevinSpaghetti/smm4h20')\n",
    "cadec = load_dataset('KevinSpaghetti/cadec')\n",
    "all_pts = load_dataset('KevinSpaghetti/all_pts', split=Split.ALL)\n",
    "pt_vocab = dict(zip(all_pts['term'], all_pts['label']))\n",
    "index_to_label = dict(zip(all_pts['label'], all_pts['term']))\n",
    "print(len(pt_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5z9aP8GY1KEu"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class AutoAugmentDataset(Dataset):\n",
    "    '''\n",
    "    A dataset that uses the labels of the classes to construct the \n",
    "    (anchor, positive) pairs used in contrastive learning.\n",
    "    Can also return the (anchor, positive, negative) pair.\n",
    "    Returns a dict that is the pair with the required keys:\n",
    "    { \n",
    "        'label': ..., \n",
    "        'anchor': ..., \n",
    "        'positive': ..., \n",
    "        'label_negative': ...,\n",
    "        'negative': ...,  }\n",
    "    '''\n",
    "\n",
    "    def __init__(self, examples, labels, return_negative = True, return_labels = True):\n",
    "        \"\"\" Inits the dataset from a pandas dataframe, positives will be drawn\n",
    "        from positives with the same anchor value, negatives will be drawn from \n",
    "        examples with other anchor values\n",
    "\n",
    "        Args:\n",
    "            examples (Sequence): the values\n",
    "            anchors (Sequence): the example column labels\n",
    "            return_negative (bool): whether to return negatives in the pair\n",
    "            return_labels (bool): whether to return the label associated with the positive and negative examples            \n",
    "        \"\"\"\n",
    "       \n",
    "        self.examples = list(examples)\n",
    "        self.labels = list(labels)\n",
    "\n",
    "        self.return_negative = return_negative\n",
    "        self.return_labels = return_labels\n",
    "\n",
    "        # to speed up positive search collect indices in examples list\n",
    "        # speeds up positive and negative sampling \n",
    "        self._positive_indices_for_label = defaultdict(list)\n",
    "        for index, (positive, label) in enumerate(zip(self.examples, self.labels)):\n",
    "            self._positive_indices_for_label[label].append(index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def get_positive(self, anchor):\n",
    "        '''Get positive for an anchor'''\n",
    "        pos_idx = random.choice(self._positive_indices_for_label[anchor])\n",
    "        return self.examples[pos_idx]\n",
    "\n",
    "    def get_negative(self, anchor):\n",
    "        '''Get a negative example for an anchor, also returns the negative_anchor'''\n",
    "        # Rejection sampling for negative sampling\n",
    "        neg_idx = random.randrange(0, len(self))\n",
    "        while neg_idx in self.positive_indices_for_label[anchor]:\n",
    "            neg_idx = random.randrange(0, len(self))\n",
    "        \n",
    "        return (self.labels[neg_idx], self.examples[neg_idx]) \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor, label = self.examples[idx], self.labels[idx]\n",
    "        \n",
    "        result = {\n",
    "            'anchor': anchor,\n",
    "            'positive': self.get_positive(label)\n",
    "        }\n",
    "        \n",
    "        if self.return_labels: result['label'] = label\n",
    "\n",
    "        if not self.return_negative:\n",
    "            return result\n",
    "\n",
    "        neg_label, neg_example = self.get_negative(anchor)\n",
    "\n",
    "        result['negative'] = neg_example\n",
    "        if self.return_labels: result['label_negative'] = neg_label\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-VHF2EW1CD1"
   },
   "outputs": [],
   "source": [
    "smm4h20_contrastive = AutoAugmentDataset(smm4h20['train']['ade'], smm4h20['train']['term_PT'], return_negative=False)\n",
    "cadec_contrastive = AutoAugmentDataset(cadec['train']['ade'], cadec['train']['term_PT'], return_negative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yUbqbcvF1YZr"
   },
   "outputs": [],
   "source": [
    "def create_dataset(df):\n",
    "  anchors = []\n",
    "  positives = []\n",
    "  for i in range(0, len(df)):\n",
    "    ex = df[i]\n",
    "    anchors.append(ex['anchor'])\n",
    "    positives.append(ex['positive'])\n",
    "  return pd.DataFrame({'anchor': anchors, 'positive': positives})\n",
    "\n",
    "create_dataset(smm4h20_contrastive).to_csv('./content/smm4h20.csv', header=True, index=False)\n",
    "create_dataset(cadec_contrastive).to_csv('./content/cadec.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xt7wMuIVSDrB",
    "outputId": "5c430b95-eb73-4e1f-f958-ada01ac4a0f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/simcse\n"
     ]
    }
   ],
   "source": [
    "%cd ./content/simcse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwSEmYRal1Ea",
    "outputId": "de8d6db7-c92d-45dd-d5d2-f3f5690becb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Process rank: -1, device: cuda:0, n_gpu: 1 distributed training: False, 16-bits training: False\n",
      "WARNING:datasets.builder:Using custom data configuration default-327bd6d370818323\n",
      "Downloading and preparing dataset csv/default to /content/simcse/./data/csv/default-327bd6d370818323/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n",
      "Downloading data files: 100% 1/1 [00:00<00:00, 7049.25it/s]\n",
      "Extracting data files: 100% 1/1 [00:00<00:00, 1239.45it/s]\n",
      "Dataset csv downloaded and prepared to /content/simcse/./data/csv/default-327bd6d370818323/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n",
      "100% 1/1 [00:00<00:00, 887.12it/s]\n",
      "[INFO|file_utils.py:1272] 2022-10-31 12:03:29,966 >> https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp0tq1v7ob\n",
      "Downloading: 100% 385/385 [00:00<00:00, 325kB/s]\n",
      "[INFO|file_utils.py:1276] 2022-10-31 12:03:30,327 >> storing https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
      "[INFO|file_utils.py:1279] 2022-10-31 12:03:30,328 >> creating metadata file for /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
      "[INFO|configuration_utils.py:445] 2022-10-31 12:03:30,328 >> loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
      "[INFO|configuration_utils.py:481] 2022-10-31 12:03:30,329 >> Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.2.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:445] 2022-10-31 12:03:30,693 >> loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
      "[INFO|configuration_utils.py:481] 2022-10-31 12:03:30,694 >> Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.2.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1685] 2022-10-31 12:03:30,694 >> Model name 'allenai/scibert_scivocab_uncased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'allenai/scibert_scivocab_uncased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "[INFO|file_utils.py:1272] 2022-10-31 12:03:31,069 >> https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpre9v3mt5\n",
      "Downloading: 100% 228k/228k [00:00<00:00, 664kB/s]\n",
      "[INFO|file_utils.py:1276] 2022-10-31 12:03:31,777 >> storing https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
      "[INFO|file_utils.py:1279] 2022-10-31 12:03:31,777 >> creating metadata file for /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
      "[INFO|tokenization_utils_base.py:1766] 2022-10-31 12:03:33,231 >> loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
      "[INFO|tokenization_utils_base.py:1766] 2022-10-31 12:03:33,231 >> loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1766] 2022-10-31 12:03:33,231 >> loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1766] 2022-10-31 12:03:33,232 >> loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1766] 2022-10-31 12:03:33,232 >> loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
      "[INFO|file_utils.py:1272] 2022-10-31 12:03:33,639 >> https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpit4nj6mi\n",
      "Downloading: 100% 442M/442M [00:06<00:00, 71.2MB/s]\n",
      "[INFO|file_utils.py:1276] 2022-10-31 12:03:39,904 >> storing https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
      "[INFO|file_utils.py:1279] 2022-10-31 12:03:39,905 >> creating metadata file for /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
      "[INFO|modeling_utils.py:1027] 2022-10-31 12:03:39,905 >> loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
      "[WARNING|modeling_utils.py:1135] 2022-10-31 12:03:43,638 >> Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForCL: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForCL from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForCL from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:1146] 2022-10-31 12:03:43,638 >> Some weights of BertForCL were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['mlp.dense.weight', 'mlp.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 80% 4/5 [00:00<00:00, 10.46ba/s]\n",
      "[INFO|trainer.py:442] 2022-10-31 12:03:49,884 >> The following columns in the training set don't have a corresponding argument in `BertForCL.forward` and have been ignored: .\n",
      "{'loss': 1.3547, 'learning_rate': 2.944078947368421e-05, 'epoch': 13.16}\n",
      " 41% 500/1216 [06:11<08:41,  1.37it/s][INFO|trainer.py:1344] 2022-10-31 12:10:01,236 >> Saving model checkpoint to /content/model/cadec-result/checkpoint-500\n",
      "[INFO|configuration_utils.py:300] 2022-10-31 12:10:01,238 >> Configuration saved in /content/model/cadec-result/checkpoint-500/config.json\n",
      "[INFO|modeling_utils.py:817] 2022-10-31 12:10:02,528 >> Model weights saved in /content/model/cadec-result/checkpoint-500/pytorch_model.bin\n",
      "{'loss': 1.013, 'learning_rate': 8.881578947368421e-06, 'epoch': 26.32}\n",
      " 82% 1000/1216 [12:43<03:00,  1.20it/s][INFO|trainer.py:1344] 2022-10-31 12:16:33,190 >> Saving model checkpoint to /content/model/cadec-result/checkpoint-1000\n",
      "[INFO|configuration_utils.py:300] 2022-10-31 12:16:33,191 >> Configuration saved in /content/model/cadec-result/checkpoint-1000/config.json\n",
      "[INFO|modeling_utils.py:817] 2022-10-31 12:16:34,524 >> Model weights saved in /content/model/cadec-result/checkpoint-1000/pytorch_model.bin\n",
      "{'train_runtime': 934.8006, 'train_samples_per_second': 1.301, 'epoch': 32.0}\n",
      "100% 1216/1216 [15:34<00:00,  1.30it/s]\n",
      "[INFO|trainer.py:1344] 2022-10-31 12:19:24,692 >> Saving model checkpoint to /content/model/cadec-result\n",
      "[INFO|configuration_utils.py:300] 2022-10-31 12:19:24,694 >> Configuration saved in /content/model/cadec-result/config.json\n",
      "[INFO|modeling_utils.py:817] 2022-10-31 12:19:26,085 >> Model weights saved in /content/model/cadec-result/pytorch_model.bin\n",
      "WARNING:__main__:Process rank: -1, device: cuda:0, n_gpu: 1 distributed training: False, 16-bits training: False\n",
      "WARNING:datasets.builder:Using custom data configuration default-a6a56cbed0119d9f\n",
      "Downloading and preparing dataset csv/default to /content/simcse/./data/csv/default-a6a56cbed0119d9f/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n",
      "Downloading data files: 100% 1/1 [00:00<00:00, 6335.81it/s]\n",
      "Extracting data files: 100% 1/1 [00:00<00:00, 675.96it/s]\n",
      "Dataset csv downloaded and prepared to /content/simcse/./data/csv/default-a6a56cbed0119d9f/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n",
      "100% 1/1 [00:00<00:00, 793.47it/s]\n",
      "[INFO|configuration_utils.py:445] 2022-10-31 12:19:36,750 >> loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
      "[INFO|configuration_utils.py:481] 2022-10-31 12:19:36,751 >> Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.2.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:445] 2022-10-31 12:19:37,110 >> loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n",
      "[INFO|configuration_utils.py:481] 2022-10-31 12:19:37,110 >> Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.2.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1685] 2022-10-31 12:19:37,110 >> Model name 'allenai/scibert_scivocab_uncased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'allenai/scibert_scivocab_uncased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "[INFO|tokenization_utils_base.py:1766] 2022-10-31 12:19:38,931 >> loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n",
      "[INFO|tokenization_utils_base.py:1766] 2022-10-31 12:19:38,931 >> loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1766] 2022-10-31 12:19:38,931 >> loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1766] 2022-10-31 12:19:38,931 >> loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1766] 2022-10-31 12:19:38,931 >> loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n",
      "[INFO|modeling_utils.py:1027] 2022-10-31 12:19:39,346 >> loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n",
      "[WARNING|modeling_utils.py:1135] 2022-10-31 12:19:44,471 >> Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForCL: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForCL from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForCL from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:1146] 2022-10-31 12:19:44,471 >> Some weights of BertForCL were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['mlp.dense.weight', 'mlp.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      " 50% 1/2 [00:00<00:00, 17.03ba/s]\n",
      "[INFO|trainer.py:442] 2022-10-31 12:19:48,909 >> The following columns in the training set don't have a corresponding argument in `BertForCL.forward` and have been ignored: .\n",
      "{'train_runtime': 212.7705, 'train_samples_per_second': 1.504, 'epoch': 32.0}\n",
      "100% 320/320 [03:32<00:00,  1.50it/s]\n",
      "[INFO|trainer.py:1344] 2022-10-31 12:23:21,687 >> Saving model checkpoint to /content/model/smm4h20-result\n",
      "[INFO|configuration_utils.py:300] 2022-10-31 12:23:21,690 >> Configuration saved in /content/model/smm4h20-result/config.json\n",
      "[INFO|modeling_utils.py:817] 2022-10-31 12:23:23,464 >> Model weights saved in /content/model/smm4h20-result/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "    --model_name_or_path allenai/scibert_scivocab_uncased \\\n",
    "    --train_file ./content/cadec.csv \\\n",
    "    --output_dir ./content/model/cadec-result \\\n",
    "    --num_train_epochs 32 \\\n",
    "    --per_device_train_batch_size 128 \\\n",
    "    --learning_rate 5e-5 \\\n",
    "    --max_seq_length 32 \\\n",
    "    --pooler_type cls \\\n",
    "    --overwrite_output_dir \\\n",
    "    --temp 0.1 \\\n",
    "    --do_train\n",
    "!python train.py \\\n",
    "    --model_name_or_path allenai/scibert_scivocab_uncased \\\n",
    "    --train_file ./content/smm4h20.csv \\\n",
    "    --output_dir ./content/model/smm4h20-result \\\n",
    "    --num_train_epochs 32 \\\n",
    "    --per_device_train_batch_size 128 \\\n",
    "    --learning_rate 5e-5 \\\n",
    "    --max_seq_length 32 \\\n",
    "    --pooler_type cls \\\n",
    "    --overwrite_output_dir \\\n",
    "    --temp 0.1 \\\n",
    "    --do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ELlv6GGrbwt2",
    "outputId": "1cd5ce62-c60a-4b97-8c92-85c690972321"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /content/model/smm4h20-result and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "WARNING:simcse.tool:Fail to import faiss. If you want to use faiss, install faiss through PyPI. Now the program continues with brute force search.\n",
      "100%|██████████| 384/384 [00:16<00:00, 23.55it/s]\n",
      "Some weights of BertModel were not initialized from the model checkpoint at /content/model/cadec-result and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "WARNING:simcse.tool:Fail to import faiss. If you want to use faiss, install faiss through PyPI. Now the program continues with brute force search.\n",
      "100%|██████████| 384/384 [00:16<00:00, 22.66it/s]\n"
     ]
    }
   ],
   "source": [
    "smm4h20_model = SimCSE(\"./content/model/smm4h20-result\")\n",
    "smm4h20_model.build_index(all_pts['term'], device='cuda')\n",
    "\n",
    "cadec_model = SimCSE(\"./content/model/cadec-result\")\n",
    "cadec_model.build_index(all_pts['term'], device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S4I4fJpsgXL3",
    "outputId": "fddedbfc-e00b-471f-9ac8-fac22ddcd148"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/KevinSpaghetti___parquet/KevinSpaghetti--smm4h20-44edae7ca61b57c9/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-97e7ee25f89e8785.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/KevinSpaghetti___parquet/KevinSpaghetti--smm4h20-44edae7ca61b57c9/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-ea79a43c34f6eb3a.arrow\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "seen, unseen = get_seen_unseen_split(smm4h20['train'], smm4h20['test'], label_col='term_PT')\n",
    "\n",
    "# change to seen to get seen split results\n",
    "smm4h20_results = smm4h20_model.search(unseen['ade'], top_k=5, device='cuda', threshold=0.01)\n",
    "real_meddras = unseen['term_PT']\n",
    "\n",
    "to_classify = len(unseen)\n",
    "correctly_classified = 0\n",
    "correct_meddra_in_top_5 = 0\n",
    "wrongly_classified = 0\n",
    "\n",
    "predicted_meddras = []\n",
    "for result_list in smm4h20_results:\n",
    "    res = []\n",
    "    for (meddra, _) in result_list:\n",
    "        res.append(meddra)\n",
    "    predicted_meddras.append(res)\n",
    "\n",
    "for (real_meddra, predicted_meddra_options) in tqdm(zip(real_meddras, predicted_meddras)):\n",
    "    if predicted_meddra_options:\n",
    "        if predicted_meddra_options[0] == real_meddra:\n",
    "            correctly_classified += 1\n",
    "        if real_meddra in predicted_meddra_options:\n",
    "            correct_meddra_in_top_5 += 1\n",
    "        else:\n",
    "            wrongly_classified += 1\n",
    "    else:\n",
    "        wrongly_classified += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2HMfOpS8DPrr",
    "outputId": "be862334-4464-44a3-e3bb-9b40798dc8f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "correct%: 0.28125, top5% 0.34375\n"
     ]
    }
   ],
   "source": [
    "print(to_classify)\n",
    "print(f\"correct%: {correctly_classified / to_classify}, top5% {correct_meddra_in_top_5 / to_classify}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yu1DKwmOEQ5G",
    "outputId": "7acaec57-d22b-48f2-f9e7-57d3081b2845"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/KevinSpaghetti___parquet/KevinSpaghetti--cadec-706fe2a599dfdc15/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-d6e5c241af5994ff.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/KevinSpaghetti___parquet/KevinSpaghetti--cadec-706fe2a599dfdc15/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-e958a5d19e7eb27d.arrow\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "seen, unseen = get_seen_unseen_split(cadec['train'], cadec['test'], label_col='term_PT')\n",
    "# change to seen to get seen split results\n",
    "cadec_results = cadec_model.search(unseen['ade'], top_k=5, device='cuda', threshold=0.01)\n",
    "real_meddras = unseen['term_PT']\n",
    "\n",
    "to_classify = len(unseen)\n",
    "correctly_classified = 0\n",
    "correct_meddra_in_top_5 = 0\n",
    "wrongly_classified = 0\n",
    "\n",
    "predicted_meddras = []\n",
    "for result_list in cadec_results:\n",
    "    res = []\n",
    "    for (meddra, _) in result_list:\n",
    "        res.append(meddra)\n",
    "    predicted_meddras.append(res)\n",
    "\n",
    "for (real_meddra, predicted_meddra_options) in tqdm(zip(real_meddras, predicted_meddras)):\n",
    "    if predicted_meddra_options:\n",
    "        if predicted_meddra_options[0] == real_meddra:\n",
    "            correctly_classified += 1\n",
    "        if real_meddra in predicted_meddra_options:\n",
    "            correct_meddra_in_top_5 += 1\n",
    "        else:\n",
    "            wrongly_classified += 1\n",
    "    else:\n",
    "        wrongly_classified += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CJgdcUb2ERpQ",
    "outputId": "60778196-63fb-4ec8-d667-1713d92ac0de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "correct%: 0.2894736842105263, top5% 0.47368421052631576\n"
     ]
    }
   ],
   "source": [
    "print(to_classify)\n",
    "print(f\"correct%: {correctly_classified / to_classify}, top5% {correct_meddra_in_top_5 / to_classify}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a49c2971c054d76b224afdd1653e6f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d58d93091f547539d632b0f12c695da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_890907bcbe9a4f0b99f323ae1e00716b",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_507bfa42c46a4833a408cbdb425cd8b8",
      "value": 2
     }
    },
    "0e49fb0361da49978ab25e3f4f3857ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "18b73b2cda9f492c970f36e8f547fa8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b5bb989bbc941339ed88a300828c8a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b9a717fa3ee84b37be66d520f274c62d",
       "IPY_MODEL_3774ec9a6e574255a78006688562de6e",
       "IPY_MODEL_7366edda2c3e4fb5b62dfb0995ca7b7b"
      ],
      "layout": "IPY_MODEL_c0279fd7382d4cf9b89fec18e862e0b8"
     }
    },
    "3774ec9a6e574255a78006688562de6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41f1e7ecd7b64bfdae4c287da23d8cef",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_81da7e86a82f4e70a8a5a4a5f418d333",
      "value": 2
     }
    },
    "3ea6d36ffdd14c11bd0b14a7c8794223": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41f1e7ecd7b64bfdae4c287da23d8cef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "439a976ff3a14b95890337d4814d16f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ea6d36ffdd14c11bd0b14a7c8794223",
      "placeholder": "​",
      "style": "IPY_MODEL_b72ed9219c3a42a6a1b0452c6e2d43e1",
      "value": "100%"
     }
    },
    "507bfa42c46a4833a408cbdb425cd8b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "54a743cc80154a1a9a742daa0932cc04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68d83eb0cfb2466a8b99cca20af8646e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_439a976ff3a14b95890337d4814d16f6",
       "IPY_MODEL_0d58d93091f547539d632b0f12c695da",
       "IPY_MODEL_d3b9e3572221476d8edb99f1ecd3260f"
      ],
      "layout": "IPY_MODEL_0a49c2971c054d76b224afdd1653e6f1"
     }
    },
    "7366edda2c3e4fb5b62dfb0995ca7b7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4a5cd45173341348193cd813ed0e2de",
      "placeholder": "​",
      "style": "IPY_MODEL_0e49fb0361da49978ab25e3f4f3857ca",
      "value": " 2/2 [00:00&lt;00:00, 56.14it/s]"
     }
    },
    "81da7e86a82f4e70a8a5a4a5f418d333": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "890907bcbe9a4f0b99f323ae1e00716b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b72ed9219c3a42a6a1b0452c6e2d43e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b9a717fa3ee84b37be66d520f274c62d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54a743cc80154a1a9a742daa0932cc04",
      "placeholder": "​",
      "style": "IPY_MODEL_18b73b2cda9f492c970f36e8f547fa8f",
      "value": "100%"
     }
    },
    "c0279fd7382d4cf9b89fec18e862e0b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2880ffc5bdb45daa6143391be4b265c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3b9e3572221476d8edb99f1ecd3260f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2880ffc5bdb45daa6143391be4b265c",
      "placeholder": "​",
      "style": "IPY_MODEL_dc2ca34783154f89b350c8e5079f2635",
      "value": " 2/2 [00:00&lt;00:00, 59.29it/s]"
     }
    },
    "d4a5cd45173341348193cd813ed0e2de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc2ca34783154f89b350c8e5079f2635": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
